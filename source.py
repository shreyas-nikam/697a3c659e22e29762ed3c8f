import uuid
import datetime
import json
import pandas as pd
# IPython.display is removed from core module imports as it's a UI/notebook-specific dependency.
# It can be re-imported in __main__ block for demonstration or handled by the consuming app.

# Define the scoring logic for inherent risk factors
# Each factor's categories are mapped to points
RISK_SCORING_TABLE = {
    'decision_criticality': {
        'Low': 1,
        'Medium': 3,
        'High': 5
    },
    'data_sensitivity': {
        'Public': 1,
        'Internal': 2,
        'Confidential': 3,
        'Regulated-PII': 5
    },
    'automation_level': {
        'Manual': 1,
        'Human-in-the-loop': 3,
        'Fully-Automated': 5
    },
    'regulatory_materiality': {
        'None': 1,
        'Low': 2,
        'Medium': 4,
        'High': 5
    }
}

# Define the thresholds for risk tiers
# Lower score means lower risk tier (e.g., Tier 3 is lowest risk)
TIER_THRESHOLDS = {
    'Tier 3': {'max_score': 8, 'description': 'Low Risk: Minimal impact, well-understood, or highly controlled.'},
    'Tier 2': {'max_score': 15, 'description': 'Medium Risk: Moderate impact, requires standard MRM oversight.'},
    'Tier 1': {'max_score': float('inf'), 'description': 'High Risk: Significant impact, requires extensive MRM oversight.'}
}

SCORING_VERSION = "v1.0"

def register_model_metadata(model_details: dict) -> dict:
    """
    Registers the model metadata, including generating audit fields.
    Validates required fields and controlled vocabularies.

    Args:
        model_details (dict): A dictionary containing the model's core metadata.

    Returns:
        dict: The complete model registration record with audit fields.

    Raises:
        ValueError: If required fields are missing/empty or if invalid values
                    are provided for risk factors.
    """
    # Validate required fields
    required_fields = [
        'model_name', 'business_use', 'domain', 'model_type',
        'decision_criticality', 'data_sensitivity', 'automation_level',
        'regulatory_materiality'
    ]
    for field in required_fields:
        if field not in model_details or not model_details[field]:
            raise ValueError(f"Required field '{field}' is missing or empty.")

    # Enforce controlled vocabularies for risk factors
    for factor, allowed_values in RISK_SCORING_TABLE.items():
        if factor in model_details and model_details[factor] not in allowed_values:
            raise ValueError(f"Invalid value '{model_details[factor]}' for '{factor}'. "
                             f"Allowed values are: {', '.join(allowed_values.keys())}")

    # Create a copy to avoid modifying the original input dict directly
    registered_details = model_details.copy()

    # Generate model_id if not provided (assume it's generated by the system)
    if 'model_id' not in registered_details or not registered_details['model_id']:
        registered_details['model_id'] = str(uuid.uuid4())

    # Add audit fields
    registered_details['created_at'] = datetime.datetime.now(datetime.timezone.utc).isoformat()
    registered_details['created_by'] = registered_details.get('created_by', 'System/Unknown Owner') # Allow override, default if not provided
    registered_details['lab_version'] = '1.0' # Or make this dynamic if needed

    return registered_details

def calculate_inherent_risk(model_metadata: dict, scoring_table: dict, tier_thresholds: dict, scoring_version: str) -> dict:
    """
    Calculates the inherent risk score and proposed tier for a model based on its metadata.

    Args:
        model_metadata (dict): The registered model's metadata, typically output from register_model_metadata.
        scoring_table (dict): The predefined scoring logic for risk factors.
        tier_thresholds (dict): The predefined thresholds for risk tiers.
        scoring_version (str): The version of the scoring logic used.

    Returns:
        dict: A dictionary containing the inherent risk score, proposed tier,
              proposed tier description, and score breakdown.
    """
    inherent_risk_score = 0
    score_breakdown = {}

    for factor, score_map in scoring_table.items():
        if factor in model_metadata:
            value = model_metadata[factor]
            # Ensure the value exists in the score_map, though register_model_metadata should prevent this
            if value in score_map:
                points = score_map[value]
                inherent_risk_score += points
                score_breakdown[factor] = {'value': value, 'points': points}
            else:
                score_breakdown[factor] = {'value': value, 'points': 0,
                                            'warning': 'Value not found in scoring map for this factor.'}
        else:
            score_breakdown[factor] = {'value': 'N/A', 'points': 0,
                                        'warning': f'Factor "{factor}" not in model metadata, cannot score.'}

    proposed_risk_tier = 'Undefined'
    tier_description = 'No tier assigned or thresholds not met.'
    # Sort tiers by max_score to ensure correct assignment for overlapping ranges, if any.
    # In this case, Tier 3 -> Tier 2 -> Tier 1 is already ordered by max_score ascending.
    sorted_tiers = sorted(tier_thresholds.items(), key=lambda item: item[1]['max_score'])

    for tier, data in sorted_tiers:
        if inherent_risk_score <= data['max_score']:
            proposed_risk_tier = tier
            tier_description = data['description']
            break

    return {
        'inherent_risk_score': inherent_risk_score,
        'proposed_risk_tier': proposed_risk_tier,
        'proposed_tier_description': tier_description,
        'score_breakdown': score_breakdown,
        'scoring_version': scoring_version
    }

def assess_model_risk(raw_model_details: dict) -> dict:
    """
    Orchestrates the model registration and inherent risk calculation process.
    This is the primary function to be called by an application.

    Args:
        raw_model_details (dict): A dictionary containing the model's core metadata
                                  as initially provided by the user.

    Returns:
        dict: The complete model record, including audit fields and
              inherent risk assessment results.

    Raises:
        ValueError: If required fields are missing, empty, or if invalid values
                    are provided for risk factors during registration.
    """
    try:
        # 1. Register the model metadata and add audit fields
        registered_model = register_model_metadata(raw_model_details)

        # 2. Calculate the inherent risk score and tier
        risk_assessment = calculate_inherent_risk(
            registered_model,
            RISK_SCORING_TABLE,
            TIER_THRESHOLDS,
            SCORING_VERSION
        )

        # 3. Update the registered model record with the risk assessment results
        registered_model.update(risk_assessment)

        return registered_model

    except ValueError as e:
        # Re-raise validation errors for the calling application to handle
        raise e
    except Exception as e:
        # Catch any other unexpected errors during the process
        raise RuntimeError(f"An unexpected error occurred during model risk assessment: {e}")

# --- Example Usage (typically in an app.py or a main script) ---
if __name__ == "__main__":
    from IPython.display import display, Markdown # Import here for demonstration purposes only

    # Display the scoring table and tier thresholds for transparency
    display(Markdown("### Inherent Risk Scoring Table"))
    display(pd.DataFrame(RISK_SCORING_TABLE).fillna('-').T)

    display(Markdown("### Proposed Risk Tier Thresholds"))
    tier_df = pd.DataFrame.from_dict(TIER_THRESHOLDS, orient='index')
    tier_df.index.name = 'Tier'
    display(tier_df)

    # Alex Chen inputs the metadata for the Predictive Maintenance Model
    predictive_maintenance_model_metadata = {
        'model_name': 'Predictive Maintenance Model v2.1',
        'business_use': 'Predict equipment failure in manufacturing to optimize maintenance schedules and reduce downtime.',
        'domain': 'Operations Efficiency',
        'model_type': 'ML classifier (time-series)',
        'decision_criticality': 'High',  # If equipment fails, production stops, high financial impact
        'data_sensitivity': 'Internal', # Uses internal operational data, not PII
        'automation_level': 'Fully-Automated', # Model directly triggers alerts/actions without human gate
        'deployment_mode': 'Real-time',
        'regulatory_materiality': 'None', # Not directly tied to financial reporting or customer interaction
        'owner_team': 'Manufacturing Operations Analytics',
        'created_by': 'Alex Chen' # Example of specifying creator
    }

    print("\n--- Attempting to assess Predictive Maintenance Model ---")
    try:
        final_model_record = assess_model_risk(predictive_maintenance_model_metadata)
        display(Markdown("### Model Metadata Successfully Registered and Risk Assessed:"))
        display(final_model_record)

        display(Markdown("\n### Summary of Inherent Risk Self-Assessment Results:"))
        display(Markdown(f"**Model Name:** `{final_model_record['model_name']}`"))
        display(Markdown(f"**Model ID:** `{final_model_record['model_id']}`"))
        display(Markdown(f"**Total Inherent Risk Score:** `{final_model_record['inherent_risk_score']}`"))
        display(Markdown(f"**Proposed Risk Tier:** `{final_model_record['proposed_risk_tier']}` - *{final_model_record['proposed_tier_description']}*"))
        display(Markdown("\n**Score Breakdown:**"))
        for factor, details in final_model_record['score_breakdown'].items():
            display(Markdown(f"- **{factor.replace('_', ' ').title()}:** Value: `{details['value']}`, Points: `{details['points']}`"))

    except ValueError as e:
        print(f"Error during model assessment: {e}")
    except RuntimeError as e:
        print(f"Runtime error during model assessment: {e}")

    print("\n--- Attempting to assess a model with missing data (will raise ValueError) ---")
    invalid_model_metadata = {
        'model_name': 'Incomplete Model',
        'business_use': 'Test missing data',
        # 'domain': 'Missing', # This field is missing
        'model_type': 'Test',
        'decision_criticality': 'Low',
        'data_sensitivity': 'Public',
        'automation_level': 'Manual',
        'regulatory_materiality': 'None'
    }
    try:
        assess_model_risk(invalid_model_metadata)
    except ValueError as e:
        print(f"Caught expected error: {e}")
    except Exception as e:
        print(f"Caught unexpected error: {e}")

    print("\n--- Attempting to assess a model with invalid vocabulary (will raise ValueError) ---")
    invalid_vocab_model_metadata = {
        'model_name': 'Invalid Vocab Model',
        'business_use': 'Test invalid vocab',
        'domain': 'Finance',
        'model_type': 'Test',
        'decision_criticality': 'Super High', # Invalid value
        'data_sensitivity': 'Public',
        'automation_level': 'Manual',
        'regulatory_materiality': 'None'
    }
    try:
        assess_model_risk(invalid_vocab_model_metadata)
    except ValueError as e:
        print(f"Caught expected error: {e}")
    except Exception as e:
        print(f"Caught unexpected error: {e}")
